{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b2f7d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "git clone https://github.com/ericharper/apex.git\n",
    "cd apex\n",
    "git checkout nm_v1.14.0\n",
    "pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" --global-option=\"--fast_layer_norm\" --global-option=\"--distributed_adam\" --global-option=\"--deprecated_fused_adam\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84906a6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import tarfile\n",
    "import wget\n",
    "import copy\n",
    "from omegaconf import OmegaConf, open_dict, read_write\n",
    "import nemo\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.metrics.wer import word_error_rate\n",
    "from nemo.utils import logging, exp_manager\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import wandb\n",
    "\n",
    "\n",
    "def read_manifest(path, train):\n",
    "    manifest = []\n",
    "    file_list = glob.glob(path)\n",
    "    \n",
    "    for filename in tqdm(sorted(file_list),desc=\"Reading manifest data\") :\n",
    "        with open(filename) as file:\n",
    "            for line in file:\n",
    "                line = line.replace(\"\\n\", \"\")\n",
    "                line = line.replace(\"\\\\\\\\\", \"/\")\n",
    "                line = line.replace(\"/Others/\", \"/OTHERS/\")\n",
    "                if train ==1:\n",
    "                    line = line.replace(\"./\", \"/mnt/sdb/jhchang/nemo/Training_RealAudio/\")\n",
    "                else:\n",
    "                    line = line.replace(\"./\", \"/mnt/sdb/jhchang/nemo/Validation_RealAudio/\")\n",
    "                data = json.loads(line)\n",
    "                manifest.append(data)\n",
    "                \n",
    "              \n",
    "    return manifest\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_charset(manifest_data):\n",
    "    charset = defaultdict(int)\n",
    "    for row in tqdm(manifest_data, desc=\"Computing character set\"):\n",
    "        text = row['text']\n",
    "        for character in text:\n",
    "            charset[character] += 1\n",
    "    return charset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aabeef",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�\\…\\{\\}\\【\\】\\・\\。\\『\\』\\、\\ー\\〜]'  # remove special character tokens\n",
    "#eng_removal_regex = '[^a-zA-Z]'  # remove test set kanji\n",
    "\n",
    "\n",
    "def remove_special_characters(data):\n",
    "    data[\"text\"] = re.sub(chars_to_ignore_regex, '', data[\"text\"]).lower().strip()\n",
    "    return data\n",
    "\n",
    "def apply_preprocessors(manifest, preprocessors):\n",
    "    for processor in preprocessors:\n",
    "        for idx in tqdm(range(len(manifest)), desc=f\"Applying {processor.__name__}\"):\n",
    "            manifest[idx] = processor(manifest[idx])\n",
    "\n",
    "    print(\"Finished processing manifest !\")\n",
    "    return manifest\n",
    "\n",
    "PREPROCESSORS = [\n",
    "    remove_special_characters\n",
    "#    ,\n",
    "#    remove_extra_kanji,\n",
    "#    remove_dakuten,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d44390",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "nemo_dir = os.path.join('/mnt/sdb/jhchang/nemo/')\n",
    "train_manifest_folder = f\"{nemo_dir}/Training_RealAudio/Manifests/*.json\"\n",
    "test_manifest_folder = f\"{nemo_dir}/Validation_RealAudio/Manifests/*.json\"\n",
    "\n",
    "if os.path.exists(f\"{nemo_dir}/Training_RealAudio/Manifests/training_merged.json\"):\n",
    "    os.remove(f\"{nemo_dir}/Training_RealAudio/Manifests/training_merged.json\")\n",
    "    os.remove(f\"{nemo_dir}/Validation_RealAudio/Manifests/test_merged.json\")\n",
    "    train_manifest_data = []\n",
    "    test_manifest_data = []\n",
    "else:\n",
    "    print(\"no existed file\")\n",
    "    \n",
    "train_manifest_data = read_manifest(train_manifest_folder, train=1)\n",
    "test_manifest_data = read_manifest(test_manifest_folder, train=0)\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data_processed = apply_preprocessors(train_manifest_data, PREPROCESSORS)\n",
    "test_data_processed = apply_preprocessors(test_manifest_data, PREPROCESSORS)\n",
    "\n",
    "\n",
    "    \n",
    "with open(f\"{nemo_dir}/Training_RealAudio/Manifests/training_merged.json\", 'w+') as outfile:\n",
    "    for row in tqdm(train_data_processed, desc=\"Writing manifesting data\"):\n",
    "        json.dump(row, outfile)\n",
    "        outfile.write('\\n')\n",
    "    \n",
    "with open(f\"{nemo_dir}/Validation_RealAudio/Manifests/test_merged.json\", 'w+') as outfile:\n",
    "    for row in tqdm(test_data_processed, desc=\"Writing manifesting data\"):\n",
    "        json.dump(row, outfile)\n",
    "        outfile.write('\\n')\n",
    "    \n",
    "    \n",
    "train_manifest_cleaned = f\"{nemo_dir}/Training_RealAudio/Manifests/training_merged.json\"\n",
    "test_manifest_cleaned = f\"{nemo_dir}/Validation_RealAudio/Manifests/test_merged.json\"\n",
    "\n",
    "\n",
    "train_charset = get_charset(train_manifest_data)\n",
    "train_dev_set = set.union(set(train_charset.keys())) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d41c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_text = [data['text'] for data in train_manifest_data]\n",
    "#dev_text = [data['text'] for data in dev_manifest_data]\n",
    "test_text = [data['text'] for data in test_manifest_data]\n",
    "train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cea2df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "char_model = nemo_asr.models.ASRModel.restore_from(f'{nemo_dir}/Model-ko-epoch 20-05-11-06-July_WER(0.0438).nemo')\n",
    "# 다른 데이터셋에 테스트할때는 보캡을 업데이트 안하는게 낫더라\n",
    "train_dev_set = set(char_model.decoder.vocabulary) | set(train_dev_set)\n",
    "char_model.change_vocabulary(new_vocabulary = list(train_dev_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac3b5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(char_model.decoder.vocabulary)\n",
    "char_model.cfg.optim.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459eb22d",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "char_model.to(\"cuda\")\n",
    "files = ['/mnt/sdb/jhchang/nemo/Validation_RealAudio/audio/DOC/20220812_2+_DOC_074.wav']\n",
    "#files = ['/mnt/sdb/jhchang/nemo/Training_RealAudio/audio/F/20220920_1_hancell_F_116.wav']\n",
    "for fname, transcription in zip(files, char_model.transcribe(paths2audio_files=files)):\n",
    "  print(f\"Audio in {fname} was rbecognized as: {transcription}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10256f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "freeze_encoder = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "freeze_encoder = bool(freeze_encoder)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def enable_bn_se(m):\n",
    "    if type(m) == nn.BatchNorm1d:\n",
    "        m.train()\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad_(True)\n",
    "\n",
    "    if 'SqueezeExcite' in type(m).__name__:\n",
    "        m.train()\n",
    "        for param in m.parameters():\n",
    "            param.requires_grad_(True)\n",
    "            \n",
    "if freeze_encoder:\n",
    "  char_model.encoder.freeze()\n",
    "  char_model.encoder.apply(enable_bn_se)\n",
    "  logging.info(\"Model encoder has been frozen, and batch normalization has been unfrozen\")\n",
    "else:\n",
    "  char_model.encoder.unfreeze()\n",
    "  logging.info(\"Model encoder has been un-frozen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1306c44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "훈련할때는 라벨옵션을 붙이고 테스트할때는 라벨옵션에 None해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a6251",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#char_model.cfg.labels = list(train_dev_set)\n",
    "cfg = copy.deepcopy(char_model.cfg)\n",
    "\n",
    "with open_dict(cfg):    \n",
    "  # Train dataset  (Concatenate train manifest cleaned and dev manifest cleaned)\n",
    "  cfg.train_ds.manifest_filepath = f\"{train_manifest_cleaned}\" #\",{dev_manifest_cleaned}\"\n",
    "  #cfg.train_ds.labels = list(train_dev_set)\n",
    "  cfg.train_ds.labels = None\n",
    "  cfg.train_ds.normalize_transcripts = False\n",
    "  cfg.train_ds.batch_size = 32\n",
    "  cfg.train_ds.num_workers = 8\n",
    "  cfg.train_ds.pin_memory = True\n",
    "  cfg.train_ds.trim_silence = False\n",
    " \n",
    "  # Validation dataset  (Use test dataset as validation, since we train using train + dev)\n",
    "  cfg.validation_ds.manifest_filepath = test_manifest_cleaned\n",
    "  #cfg.validation_ds.labels = list(train_dev_set)\n",
    "  cfg.validation_ds.labels = None\n",
    "  cfg.validation_ds.normalize_transcripts = False\n",
    "  cfg.validation_ds.batch_size = 16\n",
    "  cfg.validation_ds.num_workers = 8\n",
    "  cfg.validation_ds.pin_memory = True\n",
    "  cfg.validation_ds.trim_silence = False\n",
    "\n",
    "char_model.setup_training_data(cfg.train_ds)\n",
    "char_model.setup_multiple_validation_data(cfg.validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e936bafb",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open_dict(char_model.cfg.optim):\n",
    "  char_model.cfg.optim.lr = 0.00001  #0.01 for freezing\n",
    "  char_model.cfg.optim.betas = [0.95, 0.5]  # from paper\n",
    "  char_model.cfg.optim.weight_decay = 0.001  # Original weight decay\n",
    "  char_model.cfg.optim.sched.warmup_steps = None  # Remove default number of steps of warmup\n",
    "  char_model.cfg.optim.sched.warmup_ratio = 0.05  # 5 % warmup\n",
    "  char_model.cfg.optim.sched.min_lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce27243a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open_dict(char_model.cfg.spec_augment):\n",
    "    char_model.cfg.spec_augment.freq_masks = 2\n",
    "    char_model.cfg.spec_augment.freq_width = 25\n",
    "    char_model.cfg.spec_augment.time_masks = 2\n",
    "    char_model.cfg.spec_augment.time_width = 0.05\n",
    "\n",
    "char_model.spec_augmentation = char_model.from_config_dict(char_model.cfg.spec_augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2d562",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "WER이면 False, CER 이면 True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb8b321",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_cer = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "log_prediction = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "char_model._wer.use_cer = use_cer\n",
    "char_model._wer.log_prediction = log_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d5180",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as ptl\n",
    "\n",
    "trainer = ptl.Trainer(gpus=[1], accelerator = 'gpu', \n",
    "                      #amp_level='O1', precision=16,\n",
    "                      #devices=2, num_nodes=2, accelerator='gpu', strategy='ddp',\n",
    "                      max_epochs=100, \n",
    "                      accumulate_grad_batches=1,\n",
    "                      enable_checkpointing=False,\n",
    "                      logger=False,\n",
    "                      log_every_n_steps=100,\n",
    "                      check_val_every_n_epoch=2)\n",
    "\n",
    "char_model.set_trainer(trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6329656",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.environ.pop('NEMO_EXPM_VERSION', None)\n",
    "LANGUAGE = \"ko\"\n",
    "config = exp_manager.ExpManagerConfig(\n",
    "    exp_dir=f'experiments/lang-{LANGUAGE}/',\n",
    "    name=f\"ASR-Char-Model-Language-{LANGUAGE}\", \n",
    "    create_checkpoint_callback=True,\n",
    "    create_wandb_logger=True,\n",
    "    wandb_logger_kwargs={\"project\":'real-audio', \"job_type\":\"training\", \"log_model\":True},\n",
    "    checkpoint_callback_params=exp_manager.CallbackParams(\n",
    "        monitor=\"val_wer\",\n",
    "        mode=\"min\",\n",
    "        always_save_nemo=True,\n",
    "        save_best_model=True,\n",
    "    ),\n",
    "    \n",
    ")\n",
    "\n",
    "config = OmegaConf.structured(config)\n",
    "logdir = exp_manager.exp_manager(trainer,config)\n",
    "\n",
    "try:\n",
    "  from google import colab\n",
    "  COLAB_ENV = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "  COLAB_ENV = False\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "if COLAB_ENV:\n",
    "  %load_ext tensorboard\n",
    "  %tensorboard --logdir /content/experiments/lang-$LANGUAGE/ASR-Char-Model-Language-$LANGUAGE/\n",
    "else:\n",
    "  print(\"To use tensorboard, please use this notebook in a Google Colab environment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa4ed6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## training\n",
    "%time\n",
    "\n",
    "trainer.fit(char_model)\n",
    "#exp_manager(trainer, cfg.get(\"exp_manager\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14345b6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9af6e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "timestamp = dt.datetime.now().strftime(\"%H-%M-%d-%B\")\n",
    "save_path = f\"/mnt/sdb/jhchang/nemo/Model-ko-epoch 500-{timestamp}-from-RealAudio_loss.nemo\"\n",
    "char_model.save_to(f\"{save_path}\")\n",
    "print(f\"Model saved at path : {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d379c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be101d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "char_model = nemo_asr.models.ASRModel.restore_from(f'/mnt/sdb/jhchang/nemo/Model-ko-epoch 500-00-59-29-January-from-RealAudio_loss.nemo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ffea97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#char_model.cfg.labels = list(train_dev_set)\n",
    "cfg = copy.deepcopy(char_model.cfg)\n",
    "\n",
    "nemo_dir = os.path.join('/mnt/sdb/jhchang/nemo/')\n",
    "train_manifest_cleaned = f\"{nemo_dir}/Training_RealAudio/Manifests/training_merged.json\"\n",
    "test_manifest_cleaned = f\"{nemo_dir}/Validation_RealAudio/Manifests/test_merged.json\"\n",
    "\n",
    "with open_dict(cfg):    \n",
    "\n",
    "  # Validation dataset  (Use test dataset as validation, since we train using train + dev)\n",
    "  cfg.validation_ds.manifest_filepath = test_manifest_cleaned\n",
    "  #cfg.validation_ds.labels = list(train_dev_set)\n",
    "  cfg.validation_ds.labels = None\n",
    "  cfg.validation_ds.normalize_transcripts = False\n",
    "  cfg.validation_ds.batch_size = 8\n",
    "  cfg.validation_ds.num_workers = 8\n",
    "  cfg.validation_ds.pin_memory = True\n",
    "  cfg.validation_ds.trim_silence = False\n",
    "\n",
    "char_model.setup_multiple_validation_data(cfg.validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06cc308",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "use_cer = False #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "log_prediction = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "char_model._wer.use_cer = use_cer\n",
    "char_model._wer.log_prediction = log_prediction\n",
    "\n",
    "# Setup the test data loader and make sure the model is on GPU\n",
    "char_model.setup_test_data(test_data_config=cfg.validation_ds)\n",
    "char_model.cuda()\n",
    "char_model.eval()\n",
    "\n",
    "# We will be computing Word Error Rate (WER) metric between our hypothesis and predictions.\n",
    "# WER is computed as numerator/denominator.\n",
    "# We'll gather all the test batches' numerators and denominators.\n",
    "wer_nums = []\n",
    "wer_denoms = []\n",
    "\n",
    "# Loop over all test batches.\n",
    "# Iterating over the model's `test_dataloader` will give us:\n",
    "# (audio_signal, audio_signal_length, transcript_tokens, transcript_length)\n",
    "# See the AudioToCharDataset for more details.\n",
    "for test_batch in char_model.test_dataloader():\n",
    "        test_batch = [x.cuda() for x in test_batch]\n",
    "        targets = test_batch[2]\n",
    "        targets_lengths = test_batch[3]        \n",
    "        log_probs, encoded_len, greedy_predictions = char_model(\n",
    "            input_signal=test_batch[0], input_signal_length=test_batch[1]\n",
    "        )\n",
    "        # Notice the model has a helper object to compute WER\n",
    "        char_model._wer.update(greedy_predictions, targets, targets_lengths)\n",
    "        _, wer_num, wer_denom = char_model._wer.compute()\n",
    "        char_model._wer.reset()\n",
    "        wer_nums.append(wer_num.detach().cpu().numpy())\n",
    "        wer_denoms.append(wer_denom.detach().cpu().numpy())\n",
    "\n",
    "        # Release tensors from GPU memory\n",
    "        del test_batch, log_probs, targets, targets_lengths, encoded_len, greedy_predictions\n",
    "\n",
    "# We need to sum all numerators and denominators first. Then divide.\n",
    "print(f\"WER = {sum(wer_nums)/sum(wer_denoms)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5d6b21",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "use_cer = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "log_prediction = True #@param [\"False\", \"True\"] {type:\"raw\"}\n",
    "char_model._wer.use_cer = use_cer\n",
    "char_model._wer.log_prediction = log_prediction\n",
    "\n",
    "# Setup the test data loader and make sure the model is on GPU\n",
    "char_model.setup_test_data(test_data_config=cfg.validation_ds)\n",
    "char_model.cuda()\n",
    "char_model.eval()\n",
    "\n",
    "# We will be computing Word Error Rate (WER) metric between our hypothesis and predictions.\n",
    "# WER is computed as numerator/denominator.\n",
    "# We'll gather all the test batches' numerators and denominators.\n",
    "wer_nums = []\n",
    "wer_denoms = []\n",
    "\n",
    "# Loop over all test batches.\n",
    "# Iterating over the model's `test_dataloader` will give us:\n",
    "# (audio_signal, audio_signal_length, transcript_tokens, transcript_length)\n",
    "# See the AudioToCharDataset for more details.\n",
    "for test_batch in char_model.test_dataloader():\n",
    "        test_batch = [x.cuda() for x in test_batch]\n",
    "        targets = test_batch[2]\n",
    "        targets_lengths = test_batch[3]        \n",
    "        log_probs, encoded_len, greedy_predictions = char_model(\n",
    "            input_signal=test_batch[0], input_signal_length=test_batch[1]\n",
    "        )\n",
    "        # Notice the model has a helper object to compute WER\n",
    "        char_model._wer.update(greedy_predictions, targets, targets_lengths)\n",
    "        _, wer_num, wer_denom = char_model._wer.compute()\n",
    "        char_model._wer.reset()\n",
    "        wer_nums.append(wer_num.detach().cpu().numpy())\n",
    "        wer_denoms.append(wer_denom.detach().cpu().numpy())\n",
    "\n",
    "        # Release tensors from GPU memory\n",
    "        del test_batch, log_probs, targets, targets_lengths, encoded_len, greedy_predictions\n",
    "\n",
    "# We need to sum all numerators and denominators first. Then divide.\n",
    "print(f\"CER = {sum(wer_nums)/sum(wer_denoms)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}